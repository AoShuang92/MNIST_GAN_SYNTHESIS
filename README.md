# MNIST_GAN_SYNTHESIS
This repo contains the GAN systhesis for MNIST dataset. <br>
<br>How GAN works:<br>
1. The Discriminator learns the real and fake image; <br>
2. After passing the generated image to Discriminator, the Generator takes feedback from Discriminator. <br>
<b>Dataset:</b>60,000 training small square 28Ã—28 pixel grayscale images of handwritten single digits between 0 and 9 <br>
           training set: 60000
           testing set: 10000
           batch size: 100
<b>Model Architecture:</b> <br>
Generator: FC layers + leaky ReLu <br>
Discriminator: FC layers + leaky ReLu + Dropout (0.3) <br>
Loss Function: Cross Entropy Loss <br>
Learning Rate: 0.0002 <br>
<b>Model Training:</b>
On Discriminator: summing the loss of both real and fake to update parameters<br>
On Generator:passing the noise to Discriminator; calculating the loss then update the weighs<br>
<b> Highlights: </b><br>
1. When the Discriminator learns the fake image, the ground truth is 0;<br>
2. When passing the fake image from Generator to Discriminator, the ground truth is 1. <br>
This picture explains how GAN works:<br>
<img align='center' style="border-color:gray;border-width:2px;border-style:dashed"  src="GAN.png" width = "500px" height="300px" ></img><br>
This is what the noise looks like:<br>
<img align='center' style="border-color:gray;border-width:2px;border-style:dashed"  src="noise.png" width = "400px" height="300px" ></img>

The dataset has been divided into train and test data for cross validation. The batch size is 100 and epoch is 200. <br>
Here is the result:<br>
<img align='center' style="border-color:gray;border-width:2px;border-style:dashed"  src="sample_.png" width = "300px" height="425px" ></img>
